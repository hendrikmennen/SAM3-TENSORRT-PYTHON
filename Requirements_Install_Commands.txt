pip install "git+https://github.com/huggingface/transformers" -> Also Required If You Want To Manually Export Onnx For Different Resolution

pip install torch torchvision --upgrade
pip install "git+https://github.com/huggingface/transformers"
pip install onnx onnxscript onnxslim onnxruntime-gpu onnx_graphsurgeon opencv-python matplotlib tokenizers tabulate --upgrade
pip install nvidia-modelopt "numpy>=2.2.6" "protobuf>=4.25.1" nvidia-ml-py gradio --upgrade
pip uninstall opencv-python opencv-contrib-python opencv-python-headless -y
pip install opencv-python 


MAKE SURE TENSORRT IS INSTALLED AND ADDED TO PATH 

BELOW ARE COMMANDS FOR INSTALLING TENSORRT TO PATH LINUX :

sudo apt-get install -y --allow-downgrades \
    libnvinfer10=10.14.1.48-1+cuda12.9 \
    libnvinfer-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-headers-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-headers-plugin-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-bin=10.14.1.48-1+cuda12.9 \
    libnvinfer-dispatch10=10.14.1.48-1+cuda12.9 \
    libnvinfer-dispatch-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-lean10=10.14.1.48-1+cuda12.9 \
    libnvinfer-lean-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-plugin10=10.14.1.48-1+cuda12.9 \
    libnvinfer-plugin-dev=10.14.1.48-1+cuda12.9 \
    libnvinfer-vc-plugin10=10.14.1.48-1+cuda12.9 \
    libnvinfer-vc-plugin-dev=10.14.1.48-1+cuda12.9 \
    libnvonnxparsers10=10.14.1.48-1+cuda12.9 \
    libnvonnxparsers-dev=10.14.1.48-1+cuda12.9 \
    python3-libnvinfer=10.14.1.48-1+cuda12.9 \
    python3-libnvinfer-dev=10.14.1.48-1+cuda12.9 \
    python3-libnvinfer-lean=10.14.1.48-1+cuda12.9 \
    python3-libnvinfer-dispatch=10.14.1.48-1+cuda12.9

pip install tensorrt-cu12==10.14.1.48.post1 \
             tensorrt-dispatch-cu12==10.14.1.48.post1 \
             tensorrt-lean-cu12==10.14.1.48.post1

echo 'export PATH="/usr/src/tensorrt/bin:$PATH"' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:/usr/lib/tensorrt:${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}"' >> ~/.bashrc
source ~/.bashrc

VERIFY ALL BY USING check.py
